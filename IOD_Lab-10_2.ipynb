{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "floSqe5MiA3f"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ50HqrwiA3i"
   },
   "source": [
    "# Lab 10.2 - Deployment via Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXJlI82-iA3k"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuLXoXU9iA3m"
   },
   "source": [
    "**Note**: This notebook should work on your local machine.\n",
    "\n",
    "The purpose of this lab is to take you through the process of deploying a machine learning web app on a publicly hosted platform (Render). A trained model will be created using the Scikit-learn pipeline (combining loading, preprocessing and training steps), then separate files of Python code and text will need to be completed to make deployment possible. Firstly the app will be deployed to your local machine (so that you can view it in your browser). Once that it is successful, the files will be uploaded to a new repository you create in GitHub and then Render will read from this to host the application via a publicly accessible URL.\n",
    "\n",
    "The app will take in a text string from a user and output a prediction of whether that string is expressing positive or negative sentiment. The model is created using methods from Module 8 (Natural Language Processing). Since the training data used to create the model is small (300 records), the prediction may only be accurate around 70% of the time. In future you may wish to improve this app's performance or develop your own app in a similar manner.\n",
    "\n",
    "The following files are needed to create the app:\n",
    "\n",
    "- requirements.txt\n",
    "- app.py\n",
    "- Procfile\n",
    "- model.joblib\n",
    "- utils.py\n",
    "- templates/ (folder containing index.html)\n",
    "- static/ (folder containing css/style.css)\n",
    "\n",
    "\n",
    "Firstly we will see how a predictive model can be created as a pipe which combines the preprocessing, feature engineering and model training steps. This model is then saved as a joblib pickle file which can be reloaded at any time to avoid retraining.\n",
    "\n",
    "This trained model can be loaded within your production environment along with required packages and real-time predictions can be made by calling its predict() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55jvNWNRiA3o"
   },
   "source": [
    "Flask is a web app framework written in Python. It enables one to run application code whose output can be viewed on a browser. It is installed as a Python library via `pip install flask`. For a sample \"Hello World\" application see https://palletsprojects.com/p/flask/.\n",
    "\n",
    "Note that Flask does not scale up for use in large deployment applications (ones involving many frequent API requests)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVL-QUCEiA3o"
   },
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex\n",
      "  Downloading regex-2023.6.3-cp38-cp38-win_amd64.whl (268 kB)\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2023.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.6.0-cp38-cp38-win_amd64.whl (12.7 MB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.7-cp38-cp38-win_amd64.whl (483 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp38-cp38-win_amd64.whl (96 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp38-cp38-win_amd64.whl (18 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (4.63.0)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (1.21.3)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp38-cp38-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (21.0)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.9-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy) (1.9.0)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.1.0-py3-none-any.whl (34 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.10-cp38-cp38-win_amd64.whl (7.4 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (7.1.2)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: catalogue, srsly, murmurhash, cymem, colorama, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed blis-0.7.10 catalogue-2.0.9 colorama-0.4.6 confection-0.1.0 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 smart-open-6.3.0 spacy-3.6.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.7 thinc-8.1.10 typer-0.9.0 wasabi-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tg7rmSxKiA3q"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0wxgDMjiA3r"
   },
   "source": [
    "The training data set is `sentiments.csv`, a dataset used in the NLP module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N4qDXS4ViA3s"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv(r\"C:\\Users\\isabe\\Documents\\IOD Teaching\\TeachingData\\IOD_Data\\sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M3kt9qOPiA3u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "apuPECrQiA3v"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment source\n",
       "0                           Wow... Loved this place.          1   yelp\n",
       "1                                 Crust is not good.          0   yelp\n",
       "2          Not tasty and the texture was just nasty.          0   yelp\n",
       "3  Stopped by during the late May bank holiday of...          1   yelp\n",
       "4  The selection on the menu was great and so wer...          1   yelp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTu73GzWiA3w"
   },
   "source": [
    "Next we define a function to do some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aQ0Ja-mLiA3w"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jHqvXHWgiA3x"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0.tar.gz (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.63.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (58.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.26.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isabe\\anaconda3_1\\envs\\iod\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.1)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-3.6.0-py3-none-any.whl size=12803331 sha256=a4f18c58a1b5247941c73c2611fe80a67fe3e29c889baa624e3e920a178967f5\n",
      "  Stored in directory: c:\\users\\isabe\\appdata\\local\\pip\\cache\\wheels\\60\\48\\89\\f52d003516f5405700a0e61455b357d8dbd1c53e7822f436cb\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oppaD8YiA3x"
   },
   "source": [
    "The following NLP model is used for further preprocessing. The following steps are the same as used in Module 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8jkuC41ziA3y"
   },
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eJaHoVMYiA3z"
   },
   "outputs": [],
   "source": [
    "def convert_text(text):\n",
    "    sent = nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4opW1Y3iA30"
   },
   "outputs": [],
   "source": [
    "df['short'] = df['text'].apply(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8EvPFkRiA30"
   },
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = df['short']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prT7_T2KiA31"
   },
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eTqMYSviA32"
   },
   "outputs": [],
   "source": [
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvV4qb4hiA32"
   },
   "outputs": [],
   "source": [
    "# create a matrix of word counts from the text\n",
    "# use TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "# do the actual counting\n",
    "A = tfidf.fit_transform(X_train, y_train)\n",
    "\n",
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)\n",
    "\n",
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = tfidf.transform(X_test)\n",
    "\n",
    "# make predictions based on the test data\n",
    "predictions = classifier.predict(B)\n",
    "\n",
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsh5lFWxiA32"
   },
   "source": [
    "We will not attempt to improve on the performance in this lab as we are more interested in how to deploy the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi4u3A5oiA32"
   },
   "source": [
    "Next we create a pipeline to simplify the process of model creation. We first define a preprocessor class which applies the `clean_text` and `convert_text` functions defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xE00p38EiA33"
   },
   "outputs": [],
   "source": [
    "class preprocessor(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "         return X.apply(clean_text).apply(convert_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb8fKT8ZiA33"
   },
   "source": [
    "Next we combine the preprocessing, feature engineering and modelling steps into a single pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pm7D9sXaiA34"
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessor(), tfidf, classifier)\n",
    "pipe.fit(df['text'],df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqADinpCiA34"
   },
   "source": [
    "**Exercise**: test the resulting model on phrases of positive and negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL4XgPydiA34"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwMHti5yiA35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIVguZ7yiA35"
   },
   "source": [
    "Once satisified that we have a model ready for deployment, we can write a self-contained script that creates the model and saves it as a joblib file. By doing so from a script rather than the notebook we simplify the process when deploying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYh7yZ78iA35"
   },
   "source": [
    "**Exercise**: Review the code in model.py and run \"python model.py\" via an Anaconda prompt (Windows) or Terminal window (Mac). This creates a file model.joblib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF6btzgiiA36"
   },
   "source": [
    "Let us load this model and verify that it alone can be used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XM_C4W5aiA36"
   },
   "outputs": [],
   "source": [
    "newpipe = joblib.load(open('model.joblib','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwxzGKyPiA37"
   },
   "outputs": [],
   "source": [
    "type(newpipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7zUd5gNiA37"
   },
   "source": [
    "Testing this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8gsYyapiA37"
   },
   "outputs": [],
   "source": [
    "print(newpipe.predict(pd.Series('awesome place'))[0])\n",
    "print(newpipe.predict(pd.Series('terrible!'))[0])\n",
    "print(newpipe.predict(pd.Series('very interesting'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sChxSJ0kiA38"
   },
   "source": [
    "We can then write a self-contained script that loads the model and can make predictions on the fly. This is partially done for you in the file \"app.py\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilBRwqwbiA38"
   },
   "source": [
    "**Exercise**: Refer to app.py and fill in the missing code based on the code above using a text editor such as Spyder. Observe how it links to utils.py which contains the preprocessing functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA8IuEY2iA39"
   },
   "source": [
    "### Local hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6dXfhPhiA39"
   },
   "source": [
    "**Exercise**: Open the index.html with the text editor and fill in the missing HTML code there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOy6si7riA39"
   },
   "source": [
    "Using Anaconda prompt (Windows) or a Terminal window (Mac) run \"python app.py\". This deploys the app locally on http://127.0.0.1:5000/ (or similar) which you can then view on the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1EnLSp8iA3-"
   },
   "source": [
    "Feel free to be creative and redesign the webpage by modifying the .css and .html pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aatnOzT9iA3_"
   },
   "source": [
    "**Bonus Exercise**: Redesign the webpage by modifying the .css and .html pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIF49Fw_iA3_"
   },
   "source": [
    "### Deployment via Render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z976b75UiA3_"
   },
   "source": [
    "So far you have deployed your model on your local machine. Now we seek to deploy it publicly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0Y3GoSOiA4A"
   },
   "source": [
    "There are two additional files needed for external deployment of your model:\n",
    "- requirements.txt includes the versions of packages that are to be used with the app.\n",
    "- Procfile specifies the processes to be run on the virtualised Linux containers used to run web apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FfOqz9ViA4A"
   },
   "source": [
    "In the Procfile you will see mention of `gunicorn`. Gunicorn (Green Unicorn) manages the Flask application. It is a Python HTTP server for applications over a Web Service Gateway Interface (WSGI). It allows one to run a Python application concurrently by running multiple processes on a single machine. Further information is at https://docs.gunicorn.org/en/stable/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOsMD_aJiA4A"
   },
   "source": [
    "To update the `requirements.txt` file use the `__version__` attribute to see the version of packages being used. This ensures that your model is reproducible on other computing environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vopDOT2UiA4B"
   },
   "outputs": [],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuIh-3bziA4C"
   },
   "outputs": [],
   "source": [
    "en_core_web_sm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE-kYTFZiA4C"
   },
   "source": [
    "Log into your GitHub account (create one if you have not already done so) and create a new repository containing the following files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Mow2dpNiA4D"
   },
   "source": [
    "- requirements.txt\n",
    "- app.py\n",
    "- Procfile\n",
    "- model.joblib\n",
    "- utils.py\n",
    "- templates/ (folder containing index.html)\n",
    "- static/ (folder containing css/style.css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWFIlQ6XiA4D"
   },
   "source": [
    "Next sign up for a free account at https://dashboard.render.com/register (a Platform As A Service) by connecting via your GitHub account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBJVe116iA4E"
   },
   "source": [
    "Once signed into dashboard.render.com click \"New Web Service\" under Web Services.\n",
    "\n",
    "From \"connect GitHub account\", select the repository containing the above files.\n",
    "\n",
    "Choose a unique name for the web service and leave the root directory blank. Under \"start command\" enter \"gunicorn app:app\"\n",
    "\n",
    "Finally click \"Create Web Service\". It may take a few minutes to work but\n",
    "upon seeing \"Booting worker with pid:\" go to the url specified. An example can be seen at https://sentiment-app.onrender.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEK5KR8ZiA4F"
   },
   "source": [
    "If you managed to see your app successfully, congratulations! You now know how to deploy an app on the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6Ca3ZP1iA4G"
   },
   "source": [
    "Note that if working in part of a larger software system it is good practice to have versioning of code (e.g. with GitHub) and also make use of CI/CD software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4de77cYiA4G"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY-9z4RciA4G"
   },
   "source": [
    "More information on pipelines:\n",
    "- https://gist.github.com/amberjrivera/8c5c145516f5a2e894681e16a8095b5c\n",
    "- https://scikit-learn.org/stable/modules/compose.html#pipeline\n",
    "\n",
    "More on Flask for web app deployment:\n",
    "- https://flask.palletsprojects.com/en/1.1.x/quickstart/\n",
    "\n",
    "Deploying Flask apps on Render:\n",
    "- https://render.com/docs/deploy-flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zajzqlLHiA4H"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2023 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
